{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNu45-39Jjns",
        "outputId": "5e2e1f3b-c118-434d-95d9-0e04a6f335a0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/fyp/kaggle/fer.csv')\n",
        "\n",
        "width, height = 48, 48\n",
        "\n",
        "datapoints = data['pixels'].tolist()\n",
        "\n",
        "#getting features for training\n",
        "X = []\n",
        "for xseq in datapoints:\n",
        "    xx = [int(xp) for xp in xseq.split(' ')]\n",
        "    xx = np.asarray(xx).reshape(width, height)\n",
        "    X.append(xx.astype('float32'))\n",
        "\n",
        "X = np.asarray(X)\n",
        "X = np.expand_dims(X, -1)\n",
        "\n",
        "#getting labels for training\n",
        "y = pd.get_dummies(data['emotion'].to_numpy())\n",
        "\n",
        "#storing them using numpy\n",
        "np.save('fdataX', X)\n",
        "np.save('flabels', y)\n",
        "\n",
        "print(\"Preprocessing Done\")\n",
        "print(\"Number of Features: \"+str(len(X[0])))\n",
        "print(\"Number of Labels: \"+ str(len(y[0])))\n",
        "print(\"Number of examples in dataset:\"+str(len(X)))\n",
        "print(\"X,y stored in fdataX.npy and flabels.npy respectively\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing Done\n",
            "Number of Features: 48\n",
            "Number of Labels: 35887\n",
            "Number of examples in dataset:35887\n",
            "X,y stored in fdataX.npy and flabels.npy respectively\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdTs4TZoSilU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld_Q_SNUXvDB",
        "outputId": "1c9f6847-af00-45e1-d85a-1fd0a3e690bd"
      },
      "source": [
        "#train\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras as ks\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "width, height = 48, 48\n",
        "\n",
        "x = np.load('/content/drive/MyDrive/fyp/kaggle/fdataX.npy')\n",
        "y = np.load('/content/drive/MyDrive/fyp/kaggle/flabels.npy')\n",
        "\n",
        "x -= np.mean(x, axis=0)\n",
        "x /= np.std(x, axis=0)\n",
        "\n",
        "#for xx in range(10):\n",
        "#    plt.figure(xx)\n",
        "#    plt.imshow(x[xx].reshape((48, 48)), interpolation='none', cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "#splitting into training, validation and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=41)\n",
        "\n",
        "#saving the test samples to be used later\n",
        "np.save('modXtest', X_test)\n",
        "np.save('modytest', y_test)\n",
        "\n",
        "#desinging the CNN\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2*2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#Compliling the model with adam optimixer and categorical crossentropy loss\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the model\n",
        "model.fit(np.array(X_train), np.array(y_train),\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(np.array(X_valid), np.array(y_valid)),\n",
        "          shuffle=True)\n",
        "\n",
        "#saving the  model to be used later\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/455 [..............................] - ETA: 21s - loss: 5.0925 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0218s vs `on_train_batch_end` time: 0.0374s). Check your callbacks.\n",
            "455/455 [==============================] - 19s 42ms/step - loss: 1.9916 - accuracy: 0.2154 - val_loss: 1.8135 - val_accuracy: 0.2594\n",
            "Epoch 2/100\n",
            "455/455 [==============================] - 19s 41ms/step - loss: 1.8231 - accuracy: 0.2531 - val_loss: 1.7365 - val_accuracy: 0.2985\n",
            "Epoch 3/100\n",
            "455/455 [==============================] - 19s 42ms/step - loss: 1.7261 - accuracy: 0.2997 - val_loss: 1.6511 - val_accuracy: 0.3461\n",
            "Epoch 4/100\n",
            "455/455 [==============================] - 19s 42ms/step - loss: 1.6032 - accuracy: 0.3668 - val_loss: 1.4356 - val_accuracy: 0.4139\n",
            "Epoch 5/100\n",
            "455/455 [==============================] - 19s 42ms/step - loss: 1.5050 - accuracy: 0.4073 - val_loss: 1.3900 - val_accuracy: 0.4331\n",
            "Epoch 6/100\n",
            "455/455 [==============================] - 19s 42ms/step - loss: 1.4479 - accuracy: 0.4331 - val_loss: 1.3626 - val_accuracy: 0.4737\n",
            "Epoch 7/100\n",
            "455/455 [==============================] - 19s 42ms/step - loss: 1.4069 - accuracy: 0.4558 - val_loss: 1.3088 - val_accuracy: 0.4932\n",
            "Epoch 8/100\n",
            "455/455 [==============================] - 19s 43ms/step - loss: 1.3646 - accuracy: 0.4787 - val_loss: 1.2733 - val_accuracy: 0.5223\n",
            "Epoch 9/100\n",
            "455/455 [==============================] - 19s 43ms/step - loss: 1.3362 - accuracy: 0.4926 - val_loss: 1.2655 - val_accuracy: 0.4885\n",
            "Epoch 10/100\n",
            "455/455 [==============================] - 19s 43ms/step - loss: 1.3052 - accuracy: 0.5076 - val_loss: 1.2045 - val_accuracy: 0.5443\n",
            "Epoch 11/100\n",
            "455/455 [==============================] - 19s 43ms/step - loss: 1.2834 - accuracy: 0.5191 - val_loss: 1.1857 - val_accuracy: 0.5536\n",
            "Epoch 12/100\n",
            "455/455 [==============================] - 19s 43ms/step - loss: 1.2545 - accuracy: 0.5297 - val_loss: 1.1743 - val_accuracy: 0.5594\n",
            "Epoch 13/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.2235 - accuracy: 0.5422 - val_loss: 1.1708 - val_accuracy: 0.5659\n",
            "Epoch 14/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.2094 - accuracy: 0.5488 - val_loss: 1.1426 - val_accuracy: 0.5703\n",
            "Epoch 15/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.1908 - accuracy: 0.5568 - val_loss: 1.1214 - val_accuracy: 0.5848\n",
            "Epoch 16/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.1669 - accuracy: 0.5692 - val_loss: 1.1124 - val_accuracy: 0.5895\n",
            "Epoch 17/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.1409 - accuracy: 0.5810 - val_loss: 1.1199 - val_accuracy: 0.5978\n",
            "Epoch 18/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.1262 - accuracy: 0.5899 - val_loss: 1.0827 - val_accuracy: 0.6053\n",
            "Epoch 19/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.1027 - accuracy: 0.5991 - val_loss: 1.1125 - val_accuracy: 0.5960\n",
            "Epoch 20/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.0775 - accuracy: 0.6071 - val_loss: 1.0772 - val_accuracy: 0.6102\n",
            "Epoch 21/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.0571 - accuracy: 0.6146 - val_loss: 1.0701 - val_accuracy: 0.6003\n",
            "Epoch 22/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.0362 - accuracy: 0.6251 - val_loss: 1.0380 - val_accuracy: 0.6260\n",
            "Epoch 23/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 1.0092 - accuracy: 0.6334 - val_loss: 1.0680 - val_accuracy: 0.6130\n",
            "Epoch 24/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.9960 - accuracy: 0.6372 - val_loss: 1.0437 - val_accuracy: 0.6235\n",
            "Epoch 25/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.9747 - accuracy: 0.6501 - val_loss: 1.0241 - val_accuracy: 0.6347\n",
            "Epoch 26/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.9611 - accuracy: 0.6560 - val_loss: 1.0277 - val_accuracy: 0.6303\n",
            "Epoch 27/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.9403 - accuracy: 0.6611 - val_loss: 1.0206 - val_accuracy: 0.6412\n",
            "Epoch 28/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.9106 - accuracy: 0.6720 - val_loss: 1.0072 - val_accuracy: 0.6399\n",
            "Epoch 29/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.9001 - accuracy: 0.6783 - val_loss: 1.0478 - val_accuracy: 0.6427\n",
            "Epoch 30/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.8758 - accuracy: 0.6873 - val_loss: 1.0138 - val_accuracy: 0.6390\n",
            "Epoch 31/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.8673 - accuracy: 0.6873 - val_loss: 1.0064 - val_accuracy: 0.6399\n",
            "Epoch 32/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.8488 - accuracy: 0.6951 - val_loss: 1.0054 - val_accuracy: 0.6446\n",
            "Epoch 33/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.8379 - accuracy: 0.7000 - val_loss: 1.0153 - val_accuracy: 0.6446\n",
            "Epoch 34/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.8104 - accuracy: 0.7101 - val_loss: 1.0436 - val_accuracy: 0.6406\n",
            "Epoch 35/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.8063 - accuracy: 0.7146 - val_loss: 1.0420 - val_accuracy: 0.6424\n",
            "Epoch 36/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.7942 - accuracy: 0.7180 - val_loss: 1.0050 - val_accuracy: 0.6474\n",
            "Epoch 37/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.7716 - accuracy: 0.7266 - val_loss: 1.0327 - val_accuracy: 0.6526\n",
            "Epoch 38/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.7499 - accuracy: 0.7367 - val_loss: 1.0884 - val_accuracy: 0.6533\n",
            "Epoch 39/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.7392 - accuracy: 0.7391 - val_loss: 1.0484 - val_accuracy: 0.6545\n",
            "Epoch 40/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.7194 - accuracy: 0.7466 - val_loss: 1.0754 - val_accuracy: 0.6498\n",
            "Epoch 41/100\n",
            "455/455 [==============================] - 20s 44ms/step - loss: 0.7114 - accuracy: 0.7507 - val_loss: 1.0189 - val_accuracy: 0.6554\n",
            "Epoch 42/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6947 - accuracy: 0.7583 - val_loss: 1.0469 - val_accuracy: 0.6520\n",
            "Epoch 43/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6767 - accuracy: 0.7640 - val_loss: 1.0749 - val_accuracy: 0.6588\n",
            "Epoch 44/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6741 - accuracy: 0.7682 - val_loss: 1.0730 - val_accuracy: 0.6514\n",
            "Epoch 45/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6635 - accuracy: 0.7679 - val_loss: 1.0747 - val_accuracy: 0.6533\n",
            "Epoch 46/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6424 - accuracy: 0.7769 - val_loss: 1.0500 - val_accuracy: 0.6529\n",
            "Epoch 47/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6405 - accuracy: 0.7810 - val_loss: 1.0289 - val_accuracy: 0.6560\n",
            "Epoch 48/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6125 - accuracy: 0.7874 - val_loss: 1.0739 - val_accuracy: 0.6517\n",
            "Epoch 49/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.6117 - accuracy: 0.7903 - val_loss: 1.0828 - val_accuracy: 0.6458\n",
            "Epoch 50/100\n",
            "455/455 [==============================] - 20s 44ms/step - loss: 0.5996 - accuracy: 0.7928 - val_loss: 1.1076 - val_accuracy: 0.6610\n",
            "Epoch 51/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5846 - accuracy: 0.8017 - val_loss: 1.1628 - val_accuracy: 0.6585\n",
            "Epoch 52/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5762 - accuracy: 0.8016 - val_loss: 1.1208 - val_accuracy: 0.6650\n",
            "Epoch 53/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5595 - accuracy: 0.8078 - val_loss: 1.1289 - val_accuracy: 0.6610\n",
            "Epoch 54/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5623 - accuracy: 0.8084 - val_loss: 1.1725 - val_accuracy: 0.6505\n",
            "Epoch 55/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5525 - accuracy: 0.8124 - val_loss: 1.0967 - val_accuracy: 0.6591\n",
            "Epoch 56/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5396 - accuracy: 0.8188 - val_loss: 1.1617 - val_accuracy: 0.6548\n",
            "Epoch 57/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5227 - accuracy: 0.8244 - val_loss: 1.1354 - val_accuracy: 0.6517\n",
            "Epoch 58/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.5176 - accuracy: 0.8238 - val_loss: 1.1540 - val_accuracy: 0.6598\n",
            "Epoch 59/100\n",
            "455/455 [==============================] - 20s 44ms/step - loss: 0.5074 - accuracy: 0.8288 - val_loss: 1.1515 - val_accuracy: 0.6647\n",
            "Epoch 60/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4985 - accuracy: 0.8315 - val_loss: 1.1630 - val_accuracy: 0.6625\n",
            "Epoch 61/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4949 - accuracy: 0.8373 - val_loss: 1.1958 - val_accuracy: 0.6421\n",
            "Epoch 62/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4807 - accuracy: 0.8393 - val_loss: 1.1838 - val_accuracy: 0.6554\n",
            "Epoch 63/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4715 - accuracy: 0.8413 - val_loss: 1.2408 - val_accuracy: 0.6591\n",
            "Epoch 64/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4700 - accuracy: 0.8437 - val_loss: 1.2350 - val_accuracy: 0.6545\n",
            "Epoch 65/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4636 - accuracy: 0.8465 - val_loss: 1.1731 - val_accuracy: 0.6619\n",
            "Epoch 66/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4627 - accuracy: 0.8449 - val_loss: 1.2243 - val_accuracy: 0.6567\n",
            "Epoch 67/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4450 - accuracy: 0.8517 - val_loss: 1.2041 - val_accuracy: 0.6666\n",
            "Epoch 68/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4494 - accuracy: 0.8523 - val_loss: 1.2563 - val_accuracy: 0.6588\n",
            "Epoch 69/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4328 - accuracy: 0.8562 - val_loss: 1.3918 - val_accuracy: 0.6579\n",
            "Epoch 70/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4275 - accuracy: 0.8596 - val_loss: 1.1821 - val_accuracy: 0.6579\n",
            "Epoch 71/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4177 - accuracy: 0.8604 - val_loss: 1.2835 - val_accuracy: 0.6616\n",
            "Epoch 72/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4177 - accuracy: 0.8644 - val_loss: 1.2439 - val_accuracy: 0.6644\n",
            "Epoch 73/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.4088 - accuracy: 0.8671 - val_loss: 1.2317 - val_accuracy: 0.6579\n",
            "Epoch 74/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3991 - accuracy: 0.8689 - val_loss: 1.2987 - val_accuracy: 0.6718\n",
            "Epoch 75/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3897 - accuracy: 0.8732 - val_loss: 1.2628 - val_accuracy: 0.6678\n",
            "Epoch 76/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3887 - accuracy: 0.8739 - val_loss: 1.2374 - val_accuracy: 0.6610\n",
            "Epoch 77/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3896 - accuracy: 0.8742 - val_loss: 1.2732 - val_accuracy: 0.6659\n",
            "Epoch 78/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3809 - accuracy: 0.8773 - val_loss: 1.2475 - val_accuracy: 0.6644\n",
            "Epoch 79/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3754 - accuracy: 0.8791 - val_loss: 1.2940 - val_accuracy: 0.6625\n",
            "Epoch 80/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3759 - accuracy: 0.8776 - val_loss: 1.2401 - val_accuracy: 0.6693\n",
            "Epoch 81/100\n",
            "455/455 [==============================] - 20s 44ms/step - loss: 0.3696 - accuracy: 0.8815 - val_loss: 1.2866 - val_accuracy: 0.6709\n",
            "Epoch 82/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3465 - accuracy: 0.8878 - val_loss: 1.3783 - val_accuracy: 0.6700\n",
            "Epoch 83/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3561 - accuracy: 0.8852 - val_loss: 1.2527 - val_accuracy: 0.6582\n",
            "Epoch 84/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3521 - accuracy: 0.8870 - val_loss: 1.3273 - val_accuracy: 0.6604\n",
            "Epoch 85/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3328 - accuracy: 0.8938 - val_loss: 1.3667 - val_accuracy: 0.6650\n",
            "Epoch 86/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3393 - accuracy: 0.8917 - val_loss: 1.3704 - val_accuracy: 0.6690\n",
            "Epoch 87/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3375 - accuracy: 0.8928 - val_loss: 1.3668 - val_accuracy: 0.6591\n",
            "Epoch 88/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3221 - accuracy: 0.8962 - val_loss: 1.4627 - val_accuracy: 0.6659\n",
            "Epoch 89/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3328 - accuracy: 0.8948 - val_loss: 1.3134 - val_accuracy: 0.6632\n",
            "Epoch 90/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3220 - accuracy: 0.8983 - val_loss: 1.4013 - val_accuracy: 0.6554\n",
            "Epoch 91/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3199 - accuracy: 0.8991 - val_loss: 1.4630 - val_accuracy: 0.6604\n",
            "Epoch 92/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3111 - accuracy: 0.9016 - val_loss: 1.4781 - val_accuracy: 0.6734\n",
            "Epoch 93/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.2992 - accuracy: 0.9042 - val_loss: 1.5151 - val_accuracy: 0.6598\n",
            "Epoch 94/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.2944 - accuracy: 0.9082 - val_loss: 1.3483 - val_accuracy: 0.6619\n",
            "Epoch 95/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3018 - accuracy: 0.9046 - val_loss: 1.4323 - val_accuracy: 0.6570\n",
            "Epoch 96/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.2996 - accuracy: 0.9062 - val_loss: 1.4191 - val_accuracy: 0.6666\n",
            "Epoch 97/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.3004 - accuracy: 0.9066 - val_loss: 1.4052 - val_accuracy: 0.6635\n",
            "Epoch 98/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.2997 - accuracy: 0.9092 - val_loss: 1.3926 - val_accuracy: 0.6681\n",
            "Epoch 99/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.2857 - accuracy: 0.9100 - val_loss: 1.5936 - val_accuracy: 0.6635\n",
            "Epoch 100/100\n",
            "455/455 [==============================] - 20s 43ms/step - loss: 0.2867 - accuracy: 0.9093 - val_loss: 1.5411 - val_accuracy: 0.6573\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_tqhEcLSk_S",
        "outputId": "5e560c98-651f-45e7-af36-0770ae445efc"
      },
      "source": [
        "#test\n",
        "# load json and create model\n",
        "from __future__ import division\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "json_file = open('/content/fer.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"fer.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "truey=[]\n",
        "predy=[]\n",
        "x = np.load('/content/modXtest.npy')\n",
        "y = np.load('/content/modytest.npy')\n",
        "\n",
        "yhat= loaded_model.predict(x)\n",
        "yh = yhat.tolist()\n",
        "yt = y.tolist()\n",
        "count = 0\n",
        "\n",
        "for i in range(len(y)):\n",
        "    yy = max(yh[i])\n",
        "    yyt = max(yt[i])\n",
        "    predy.append(yh[i].index(yy))\n",
        "    truey.append(yt[i].index(yyt))\n",
        "    if(yh[i].index(yy)== yt[i].index(yyt)):\n",
        "        count+=1\n",
        "\n",
        "acc = (count/len(y))*100\n",
        "\n",
        "#saving values for confusion matrix and analysis\n",
        "np.save('truey', truey)\n",
        "np.save('predy', predy)\n",
        "print(\"Predicted and true label values saved\")\n",
        "print(\"Accuracy on test set :\"+str(acc)+\"%\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "Predicted and true label values saved\n",
            "Accuracy on test set :64.1961549178044%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}