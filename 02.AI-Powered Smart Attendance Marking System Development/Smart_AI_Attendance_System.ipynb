{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#SMART AI Attendance System Using Face Recognition\n",
        "\n",
        "\n",
        "SVM=It's a powerful and versatile machine learning algorithm used for both classification and regression tasks.\n"
      ],
      "metadata": {
        "id": "JumsH7Xn6-Lo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "QEAznGQH2q5Q",
        "outputId": "22b35c98-ebe2-4f9f-d0e6-4163a9cfdc3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Name:fdf\n",
            "Enter Your Index Number:7567567\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e8d85ca24373>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex_No\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/fdf'"
          ]
        }
      ],
      "source": [
        "#Dataset Creation\n",
        "\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "\n",
        "cascade = 'haarcascade_frontalface_default.xml'\n",
        "detector = cv2.CascadeClassifier(cascade)\n",
        "\n",
        "\n",
        "Name = str(input(\"Enter your Name:\"))\n",
        "Index_No = int(input(\"Enter Your Index Number:\"))\n",
        "dataset = 'dataset'\n",
        "sub_data = Name\n",
        "path = os.path.join(dataset, sub_data)\n",
        "\n",
        "if not os.path.isdir(path):\n",
        "  os.mkdir(path)\n",
        "  print(sub_data)\n",
        "info = [str(Name), str(Index_No)]\n",
        "with open('student.csv','a') as csvFile:\n",
        "    write = csv.writter(csvFile)\n",
        "    write.writerow(info)\n",
        "csvFile.close()\n",
        "\n",
        "\n",
        "\n",
        "print (\"Starting Video Stream...\")\n",
        "cam = cv2.VideoCapture(0)\n",
        "time.sleep(2.0)\n",
        "total = 0\n",
        "\n",
        "while total < 50:\n",
        "      print(total)\n",
        "      _,frame = cam.read()\n",
        "      img =imutils.resize(frame, width =400)\n",
        "      rects = detector.detectMultiScale(\n",
        "         cv2.cvtColor(img,cv2.COLOR_BGR2GRAY), SCALEfACTOR=1.1,\n",
        "         minNeighbors=5, minSize=(30,30))\n",
        "\n",
        "      for(x, y, w, h) in rects:\n",
        "        cv2.rectangle(frame, (x,y), (x + w, y +h),(0,255,0),2)\n",
        "        p = os.path.sep.join([path, \"{}.png\".format(str(total).zfill(5))])\n",
        "\n",
        "        cv2.imwrite(p,img)\n",
        "        total += 1\n",
        "\n",
        "\n",
        "      cv2.imshow(\"Frame\", frame)\n",
        "      key = cv2.waitKey(1) & 0xFF\n",
        "      if key == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-Processing Embeddings\n",
        "\n",
        "\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import pickle\n",
        "import imutils\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "dataset = \"dataset\"\n",
        "embeddingFile = \"output/embeddings.pickle\"\n",
        "embeddingModel = \"openface_nn4.small2.v1.t7\"\n",
        "\n",
        "prototxt = \"model/deploy.prototxt\"\n",
        "model= \"model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "#loading caffe model for face detection\n",
        "\n",
        "# Detecting face from the Image via Caffe deep learning\n",
        "detector = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
        "\n",
        "\n",
        "#loading pytorch model file for extract facial embeddings\n",
        "#extracting facial embeddings via deep learning feature extraction\n",
        "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
        "\n",
        "\n",
        "#getting image paths\n",
        "imagePaths = list(paths.list_images(dataset))\n",
        "\n",
        "\n",
        "knownEmbeddings = []\n",
        "knownNames = []\n",
        "\n",
        "\n",
        "total = 0\n",
        "conf = 0.5 #confidence level\n",
        "\n",
        "#starting reading images one by one to apply face detection and embedding\n",
        "\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "  print(\"Processing image {}/{}\".format(i + 1,len(imagePaths)))\n",
        "  name=imagePath.split(os.path.sep)[-2]\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = imutils.resize(image,width=600)\n",
        "  (h, w) = image.shape[:2]\n",
        "\n",
        "  #Converting image to blob for dnn face detection\n",
        "  imageBlob = cv2.dnn.blobFromImage(\n",
        "      cv2.resize(image, (300,300)),1.0, (300,300),(104.0,177.0,123.0), swapRB= False )\n",
        "\n",
        "#setting input blob mage\n",
        "  detector.setInput(imageBlob)\n",
        "\n",
        "  detections=detector.forward()\n",
        "\n",
        "  if len(detections) > 0:\n",
        "    i = np.argmax(detections[0,0, :, 2])\n",
        "    confidence = detections[ 0, 0, i,2]\n",
        "\n",
        "    if confidence > conf:\n",
        "      #ROI range of interest\n",
        "      box =detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "      (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "      face = image[startY:endY, startX:endX]\n",
        "      (fH, fW) = face.shape[:2]\n",
        "\n",
        "\n",
        "      if fW <20 or fH<20:\n",
        "          continue\n",
        "\n",
        "      #image to blob for face\n",
        "      faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96,96), (0, 0, 0), swapRB=False)\n",
        "\n",
        "      #facial features embedder input image faceblob\n",
        "      embedder.setinput(faceBlob)\n",
        "      vec = embedder . forward()\n",
        "      knownNames.append(name)\n",
        "      knownEmbeddings.append(vec.flatten())\n",
        "      total += 1\n",
        "\n",
        "\n",
        "print(\"Embedding:{0}\".format(total))\n",
        "data = {\"embeddings\": knownEmbeddings, \"names\":knownNames}\n",
        "f = open(embeddingFile, \"wb\") #wb= write binary\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()\n",
        "print(\"Process Completed!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "7mD-35v4JCzt",
        "outputId": "70bac3b1-2f75-44d7-8244-5dfdcd47e9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-65f49d1082c1>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Detecting face from the Image via Caffe deep learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"model/deploy.prototxt\" in function 'ReadProtoFromTextFile'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with Machine Learning"
      ],
      "metadata": {
        "id": "1D8D5aD8XPR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using sklearn\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "\n",
        "\n",
        "#Initialization of embedding & recognizer\n",
        "embeddingFile = \"output/embeddings.pickle\"\n",
        "recognizerFile = \"output/recognizer.pickle\"\n",
        "labelEncFile = \"output/le.pickle\"\n",
        "\n",
        "\n",
        "print(\"Loading face embeddings...\")\n",
        "data = pickle.loads(open(embeddingFile, \"rb\").read())\n",
        "\n",
        "\n",
        "print(\"Encoding Lables...\")\n",
        "labelEnc = LabelEncoder()\n",
        "labels = labelEnc.fit_transform(data[\"names\"])\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training Model...\")\n",
        "recognizer = SVC(C=1.0, kernel =\"linear\", probability=True)\n",
        "recognizer.fit(data[\"embeddings\"], labels)\n",
        "\n",
        "\n",
        "f = open(recognizerFile, \"wb\")\n",
        "f.write(pickle.dumps(recognizer))\n",
        "f.close()\n",
        "\n",
        "f=open(labelEncFile, \"wb\")\n",
        "f.write(pickle,dumps(LabelEnc))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Zj347fKFW_Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recognizing Person"
      ],
      "metadata": {
        "id": "w_rxPAmDcG8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "embeddingModel = \"openface.nn4.small2.v1.t7\"\n",
        "\n",
        "\n",
        "enbeddingFile = \"output/embeddings.pickle\"\n",
        "recognizerFile = \"output/recognizer.pickle\"\n",
        "labelEncFile = \"output/le.pickle\"\n",
        "conf = 0.5\n",
        "\n",
        "\n",
        "print(\"Loading Face Detector...\")\n",
        "protxt = \"model/deploy.protxt\"\n",
        "model = \"model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "detector = cv2.dnn.readNetFromCaffe(prototxt,model)\n",
        "\n",
        "\n",
        "print(\"Loading Face Recognizer...\")\n",
        "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
        "\n",
        "recognizer = pickle.loads(open(recognizerFile, \"rb\").reada())\n",
        "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
        "\n",
        "\n",
        "Index_No=\"\"\n",
        "box = []\n",
        "print(\"Starting Video Stream...\")\n",
        "cam = cv2.VideoCapture(1)\n",
        "time.sleep(2.0)\n",
        "\n",
        "while True:\n",
        "    _, frame = cam.read()\n",
        "    frame = imutils.resize(frame, width=600)\n",
        "    (h, w) = frame.shape[:2]\n",
        "    #parse to the BLOB\n",
        "    imageBlob = cv2.dnn.blobFromImage(cv2.resize(frame, (300,  300)),1.0, (300, 300),(104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
        "\n",
        "detector.setInput(imageBlob)\n",
        "    detections = detector.forward()\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "        if confidence > conf:\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "            face = frame[startY:endY, startX:endX]\n",
        "            (fH, fW) = face.shape[:2]\n",
        "\n",
        "            if fW < 20 or fH < 20:\n",
        "                continue\n",
        "\n",
        "            faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
        "            embedder.setInput(faceBlob)\n",
        "            vec = embedder.forward()\n",
        "\n",
        "            preds = recognizer.predict_proba(vec)[0]\n",
        "            j = np.argmax(preds)\n",
        "            proba = preds[j]\n",
        "            name = le.classes_[j]\n",
        "            text = \"{}  : {:.2f}%\".format(name, proba * 100)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 0, 255), 2)\n",
        "            cv2.putText(frame, text, (startX, y),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "ai47O3GdcXhx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "0b60b4b8-0230-41fa-d54b-eb15ecbcb2bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-71dafdfed8af>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    detections = detector.forward()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KSce4EujMHGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recognition Person with CSV Database"
      ],
      "metadata": {
        "id": "BY0rR1EoKfTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Iterable\n",
        "import numpy as np\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import csv\n",
        "\n",
        "\n",
        "def flatten(lis):\n",
        "    for item in lis:\n",
        "        if isinstance(item, Iterable) and not isinstance(item, str):\n",
        "            for x in flatten(item):\n",
        "                yield x\n",
        "        else:\n",
        "            yield item\n",
        "\n",
        "\n",
        "embeddingFile = \"output/embeddings.pickle\"\n",
        "embeddingModel = \"openface_nn4.small2.v1.t7\"\n",
        "recognizerFile = \"output/recognizer.pickle\"\n",
        "labelEncFile = \"output/le.pickle\"\n",
        "conf = 0.5\n",
        "\n",
        "print(\"[INFO] loading face detector...\")\n",
        "prototxt = \"model/deploy.prototxt\"\n",
        "model = \"model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "detector = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
        "\n",
        "print(\"[INFO] loading face recognizer...\")\n",
        "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
        "\n",
        "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
        "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
        "\n",
        "Roll_Number = \"\"\n",
        "box = []\n",
        "print(\"[INFO] starting video stream...\")\n",
        "cam = cv2.VideoCapture(0)\n",
        "time.sleep(2.0)\n",
        "\n",
        "while True:\n",
        "    _, frame = cam.read()\n",
        "    frame = imutils.resize(frame, width=600)\n",
        "    (h, w) = frame.shape[:2]\n",
        "    imageBlob = cv2.dnn.blobFromImage(\n",
        "        cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
        "        (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
        "\n",
        "    detector.setInput(imageBlob)\n",
        "    detections = detector.forward()\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "        if confidence > conf:\n",
        "\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "            face = frame[startY:endY, startX:endX]\n",
        "            (fH, fW) = face.shape[:2]\n",
        "\n",
        "            if fW < 20 or fH < 20:\n",
        "                continue\n",
        "\n",
        "            faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
        "            embedder.setInput(faceBlob)\n",
        "            vec = embedder.forward()\n",
        "\n",
        "            preds = recognizer.predict_proba(vec)[0]\n",
        "            j = np.argmax(preds)\n",
        "            proba = preds[j]\n",
        "            name = le.classes_[j]\n",
        "            with open('student.csv', 'r') as csvFile:\n",
        "                reader = csv.reader(csvFile)\n",
        "                for row in reader:\n",
        "                    box = np.append(box, row)\n",
        "                    name = str(name)\n",
        "                    if name in row:\n",
        "                        person = str(row)\n",
        "                        print(name)\n",
        "                listString = str(box)\n",
        "                print(box)\n",
        "                if name in listString:\n",
        "                    singleList = list(flatten(box))\n",
        "                    listlen = len(singleList)\n",
        "                    Index = singleList.index(name)\n",
        "                    name = singleList[Index]\n",
        "                    Roll_Number = singleList[Index + 1]\n",
        "                    print(Roll_Number)\n",
        "\n",
        "            text = \"{} : {} : {:.2f}%\".format(name, Roll_Number, proba * 100)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
        "                          (0, 0, 255), 2)\n",
        "            cv2.putText(frame, text, (startX, y),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "96zKenvvKd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RecognizingPersonwithCSVDatabase"
      ],
      "metadata": {
        "id": "PVPatbUpMKlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Iterable\n",
        "import numpy as np\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import csv\n",
        "\n",
        "\n",
        "def flatten(lis):\n",
        "    for item in lis:\n",
        "        if isinstance(item, Iterable) and not isinstance(item, str):\n",
        "            for x in flatten(item):\n",
        "                yield x\n",
        "        else:\n",
        "            yield item\n",
        "\n",
        "\n",
        "embeddingFile = \"output/embeddings.pickle\"\n",
        "embeddingModel = \"openface_nn4.small2.v1.t7\"\n",
        "recognizerFile = \"output/recognizer.pickle\"\n",
        "labelEncFile = \"output/le.pickle\"\n",
        "conf = 0.5\n",
        "\n",
        "print(\"[INFO] loading face detector...\")\n",
        "prototxt = \"model/deploy.prototxt\"\n",
        "model = \"model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "detector = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
        "\n",
        "print(\"[INFO] loading face recognizer...\")\n",
        "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
        "\n",
        "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
        "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
        "\n",
        "Index_No = \"\"\n",
        "box = []\n",
        "print(\"[INFO] starting video stream...\")\n",
        "cam = cv2.VideoCapture(0)\n",
        "time.sleep(2.0)\n",
        "\n",
        "while True:\n",
        "    _, frame = cam.read()\n",
        "    frame = imutils.resize(frame, width=600)\n",
        "    (h, w) = frame.shape[:2]\n",
        "    imageBlob = cv2.dnn.blobFromImage(\n",
        "        cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
        "        (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
        "\n",
        "    detector.setInput(imageBlob)\n",
        "    detections = detector.forward()\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "        if confidence > conf:\n",
        "\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "            face = frame[startY:endY, startX:endX]\n",
        "            (fH, fW) = face.shape[:2]\n",
        "\n",
        "            if fW < 20 or fH < 20:\n",
        "                continue\n",
        "\n",
        "            faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
        "            embedder.setInput(faceBlob)\n",
        "            vec = embedder.forward()\n",
        "\n",
        "            preds = recognizer.predict_proba(vec)[0]\n",
        "            j = np.argmax(preds)\n",
        "            proba = preds[j]\n",
        "            name = le.classes_[j]\n",
        "            with open('student.csv', 'r') as csvFile:\n",
        "                reader = csv.reader(csvFile)\n",
        "                for row in reader:\n",
        "                    box = np.append(box, row)\n",
        "                    name = str(name)\n",
        "                    if name in row:\n",
        "                        person = str(row)\n",
        "                        print(name)\n",
        "                listString = str(box)\n",
        "                print(box)\n",
        "                if name in listString:\n",
        "                    singleList = list(flatten(box))\n",
        "                    listlen = len(singleList)\n",
        "                    Index = singleList.index(name)\n",
        "                    name = singleList[Index]\n",
        "                    Roll_Number = singleList[Index + 1]\n",
        "                    print(Roll_Number)\n",
        "\n",
        "            text = \"{} : {} : {:.2f}%\".format(name, Roll_Number, proba * 100)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
        "                          (0, 0, 255), 2)\n",
        "            cv2.putText(frame, text, (startX, y),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UGFT4ThmMLJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}